{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Folder init ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder './synthetic_ds' already exists.\n",
      "Folder './batchsize_20' created successfully.\n",
      "Folder './batchsize_40' created successfully.\n",
      "Folder './batchsize_80' created successfully.\n",
      "Folder './batchsize_100' created successfully.\n",
      "Folder './batchsize_200' created successfully.\n",
      "Folder './batchsize_250' created successfully.\n",
      "Folder './batchsize_400' created successfully.\n",
      "Folder './batchsize_500' created successfully.\n",
      "Folder './batchsize_500' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "nn = 40000 # for synthetic data size\n",
    "batch_size = [20, 40, 80, 100, 200, 250, 400, 500]\n",
    "batch_count = [int(nn/bs) for bs in batch_size]\n",
    "exa_path = './synthetic_ds'\n",
    "\n",
    "folder_names = [exa_path]\n",
    "for bs in batch_size:\n",
    "    folder_names.append(\"./batchsize_\" + str(bs))\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "folder_name_sum = './outputs_sum'\n",
    "if not os.path.exists(folder_name_sum):\n",
    "    os.makedirs(folder_name_sum)\n",
    "    print(f\"Folder '{folder_name_sum}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name_sum}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. log data preprocessing (ExaGeostat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_zvecs = 45  # total number of zvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 log file summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa_files = [os.path.join(exa_path, 'log_40000_univariate_matern_stationary_') + str(i) for i in range(1, n_zvecs+1)] # 50 is the replicates\n",
    "data = []\n",
    "# Open the input file and create a CSV output file\n",
    "for i, exa_file in enumerate(exa_files):\n",
    "    with open(exa_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        last_three_lines = lines[-4:]\n",
    "        for line in last_three_lines:\n",
    "            if 'Total Number of Iterations=' in line:\n",
    "                iterations = int(line.split('=')[1])\n",
    "            elif 'Total Optimization Time= ' in line:\n",
    "                time = float(line.split('=')[1].strip().split(' ')[0])\n",
    "            elif 'Found Maximum at (' in line:\n",
    "                max_values = tuple(map(float, line.split('(')[1].split(',')[:3]))\n",
    "            elif 'LogLi:' in line:\n",
    "                llh = float(line.split(':')[1])\n",
    "    data.append([iterations, time] + list(max_values) + [llh])\n",
    "\n",
    "# Write the extracted information to a CSV file\n",
    "with open(os.path.join(folder_name_sum, 'output_full.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Iterations', 'Time', 'variance', 'range', 'smoothness', 'log-likelihood'])\n",
    "    # Write the data rows\n",
    "    writer.writerows(data)\n",
    "\n",
    "# Read data from CSV file\n",
    "data = pd.read_csv(os.path.join(folder_name_sum, 'output_full.csv'))\n",
    "\n",
    "# Convert data to pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save dataframe to original file\n",
    "df.to_csv(os.path.join(folder_name_sum, 'output_full.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. bash file init for vecchia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 bash file created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bs = len(batch_size)\n",
    "\n",
    "with open(\"run_script.sh\", \"w\") as f:\n",
    "    for i in range(1, n_zvecs + 1):\n",
    "        for j in range(num_bs):\n",
    "            # construct the command line string\n",
    "            cmd = f\"./bin/test_dvecchia_batch -N {batch_size[j]}:1 -s --batchCount {batch_count[j]} --vecchia --maxiter 2000 --kernel 1 --num_loc 40000 --zvecs {i} --tol 1e-10\\n\"\n",
    "            f.write(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to go run `bash ./data/run_script.sh` in the `~/testing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Summary log summerized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def read_files_and_concatenate(file_pattern, column_names, output_file):\n",
    "    \"\"\"\n",
    "    Read multiple CSV files with the same format and concatenate them into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_pattern (str): The file pattern to match, e.g. 'data_*.csv'\n",
    "    column_names (list of str): The column names for the output DataFrame\n",
    "    output_file (str): The filename to save the output DataFrame to\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create an empty DataFrame to hold the data\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Iterate over all matching files\n",
    "    for filename in glob.glob(file_pattern):\n",
    "        # Load the current file into a DataFrame\n",
    "        temp_df = pd.read_csv(filename)\n",
    "        temp_df.columns = column_names\n",
    "        # Append the data from the current file to the main DataFrame\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    # Save the main DataFrame to a new file\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to hold the data\n",
    "col_name = ['Iterations', 'Time', 'variance', 'range', 'smoothness', 'log-likelihood']\n",
    "file_pattern = [f'batchsize_{bs}/sum_40000_{bs}_*.csv' for bs in batch_size]\n",
    "output_file = [os.path.join(folder_name_sum, f'output_{bs}.csv') for bs in batch_size]\n",
    "for k in range(len(batch_size)):\n",
    "    read_files_and_concatenate(file_pattern[k], col_name, output_file[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_all = [20, 40, 80, 100, 200, 250, 400, 500, 'full']\n",
    "n_fea = len(batch_size_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = './fig_tol'\n",
    "if os.path.exists(fig_path):\n",
    "    print(fig_path + ' exists!')\n",
    "else:\n",
    "    os.mkdir(fig_path)\n",
    "    print(fig_path + ' is created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "# Set the default font size\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "def plot_time_boxplot(file_names, indic):\n",
    "    \"\"\"\n",
    "    Plot a boxplot of the 'Time' column for each CSV file in the list of file names.\n",
    "    \"\"\"\n",
    "    # Create an empty list to store the time data\n",
    "    time_data = []\n",
    "\n",
    "    # Loop through the file names and extract the \"Time\" column from each CSV file\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name)\n",
    "        time_data.append(df[indic])\n",
    "\n",
    "    # Create a boxplot of the time data with x-axis ticks for each file name\n",
    "    bp = plt.boxplot(time_data, \n",
    "                    patch_artist=True,\n",
    "                    # notch=True, \n",
    "                     widths=0.4)\n",
    "        # Set the boxplot colors\n",
    "    colors = plt.cm.Blues(np.linspace(0.1, 0.9, 9))\n",
    "\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        \n",
    "    # Set the line width for the median line\n",
    "    for median in bp['medians']:\n",
    "        median.set_linewidth(2)\n",
    "        \n",
    "    # Set the line width for the whiskers\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set_linewidth(1.5)\n",
    "    \n",
    "    \n",
    "    plt.xticks(range(1, len(file_names) + 1), batch_size_all)\n",
    "\n",
    "    # Add a title and axis labels\n",
    "    if indic == 'Time':\n",
    "        plt.title('Boxplot of total time')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        plt.yscale('log')\n",
    "        plt.ylabel('Seconds')\n",
    "    elif indic == 'Iterations':\n",
    "        plt.title('Boxplot of total iterations')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        # plt.yscale('log')\n",
    "        plt.ylabel('Iterations')\n",
    "    elif indic == 'variance':\n",
    "        plt.title(r'Boxplot of $\\hat\\sigma$')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=1.0, color='red', linestyle='--', label=r'$\\sigma=1$')\n",
    "        # Add a legend\n",
    "        plt.legend(loc='upper left')\n",
    "    elif indic == 'range':\n",
    "        plt.title(r'Boxplot of $\\hat\\beta$')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        plt.ylim(0.075, 0.15)\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=0.1, color='red', linestyle='--', label=r'$\\beta=0.1$')\n",
    "        # Add a legend\n",
    "        plt.legend(loc='upper left')\n",
    "    elif indic == 'smoothness':\n",
    "        plt.title(r'Boxplot of $\\hat\\nu$')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        plt.ylim(0.45, 0.55)\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=0.5, color='red', linestyle='--', label=r'$\\nu=0.5$')\n",
    "        # Add a legend\n",
    "        plt.legend(loc='upper left')\n",
    "    elif indic == 'log-likelihood':\n",
    "        plt.title(r'Boxplot of log-likelihood')\n",
    "        plt.xlabel('batch size (n = 40k)')\n",
    "        plt.ylim(-900, 2800)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(os.path.join(fig_path, indic) + str('.pdf'), format = 'pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = [os.path.join(folder_name_sum, f'output_{bs}.csv') for bs in batch_size_all]\n",
    "plot_time_boxplot(output_file, indic='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='log-likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='smoothness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "185e5c47242a5ceaa23e29ada14173afc2d86b943e6603ddddbe3fb4d7ad104d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
