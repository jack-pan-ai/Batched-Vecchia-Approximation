{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Please modify the fig title in the section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Folder init ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [1.0, 0.1, 0.5]\n",
    "bv = True\n",
    "dep = True\n",
    "knn = False\n",
    "grouping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "nn = 1000 # for synthetic data size\n",
    "n_zvecs = 100\n",
    "batch_size = [2, 5, 10, 20, 40]\n",
    "batch_count = [int(nn/bs) for bs in batch_size]\n",
    "exa_path = './synthetic_ds'\n",
    "\n",
    "folder_names = [exa_path]\n",
    "for bs in batch_size:\n",
    "    if dep:\n",
    "        folder_names.append(\"./batchsize_\" + str(bs)+ \"_\" + str(bs))\n",
    "    else:\n",
    "        folder_names.append(\"./batchsize_\" + str(bs)+ \"_0\")\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "folder_name_sum = './outputs_sum'\n",
    "if not os.path.exists(folder_name_sum):\n",
    "    os.makedirs(folder_name_sum)\n",
    "    print(f\"Folder '{folder_name_sum}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name_sum}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nn/bs for bs in batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. log data preprocessing (ExaGeostat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 log file summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa_files = [os.path.join(exa_path, 'log_1000_univariate_matern_stationary_') + str(i) for i in range(1, n_zvecs+1)] # 50 is the replicates\n",
    "data = []\n",
    "# Open the input file and create a CSV output file\n",
    "for i, exa_file in enumerate(exa_files):\n",
    "    with open(exa_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        last_three_lines = lines[-4:]\n",
    "        for line in last_three_lines:\n",
    "            if 'Total Number of Iterations=' in line:\n",
    "                iterations = int(line.split('=')[1])\n",
    "            elif 'Total Optimization Time= ' in line:\n",
    "                time = float(line.split('=')[1].strip().split(' ')[0])\n",
    "            elif 'Found Maximum at (' in line:\n",
    "                max_values = tuple(map(float, line.split('(')[1].split(',')[:3]))\n",
    "            elif 'LogLi:' in line:\n",
    "                llh = float(line.split(':')[1])\n",
    "    data.append([iterations, time] + list(max_values) + [llh])\n",
    "\n",
    "# Write the extracted information to a CSV file\n",
    "with open(os.path.join(folder_name_sum, 'output_full.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Iterations', 'Time', 'variance', 'range', 'smoothness', 'log-likelihood'])\n",
    "    # Write the data rows\n",
    "    writer.writerows(data)\n",
    "\n",
    "# Read data from CSV file\n",
    "data = pd.read_csv(os.path.join(folder_name_sum, 'output_full.csv'))\n",
    "\n",
    "# Convert data to pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save dataframe to original file\n",
    "df.to_csv(os.path.join(folder_name_sum, 'output_ExaGeoStat.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./outputs_sum/output_exact.csv', header=None, index_col=None, sep=' ', \\\n",
    "#     names = ['ine',  'variance', 'range', 'smoothness', 'Time', 'Iterations', 'log-likelihood'])\n",
    "# data.to_csv('./outputs_sum/output_ExaGeoStat.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. bash file init for vecchia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 bash file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some args to be noticed, such as tolerance, batchCount, etc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bs = len(batch_size)\n",
    "\n",
    "with open(\"run_script.sh\", \"w\") as f:\n",
    "    for i in range(1, n_zvecs + 1):\n",
    "        for j in range(num_bs):\n",
    "            # construct the command line string\n",
    "            if dep:\n",
    "                cmd = f\"./bin/test_dvecchia_batch -N {batch_size[j]}:1 -s --batchCount {batch_count[j]} --vecchia --maxiter 2000 --kernel 1 --num_loc 1000 --zvecs {i} --tol 9\\n\"\n",
    "            else:\n",
    "                cmd = f\"./bin/test_dvecchia_batch -N {batch_size[j]}:1 -s --batchCount {batch_count[j]} --maxiter 2000 --kernel 1 --num_loc 1000 --zvecs {i} --tol 9\\n\"\n",
    "            f.write(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to go run `bash ./data/run_script.sh` in the `~/testing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Summary log summerized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def read_files_and_concatenate(file_pattern, column_names, output_file):\n",
    "    \"\"\"\n",
    "    Read multiple CSV files with the same format and concatenate them into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_pattern (str): The file pattern to match, e.g. 'data_*.csv'\n",
    "    column_names (list of str): The column names for the output DataFrame\n",
    "    output_file (str): The filename to save the output DataFrame to\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create an empty DataFrame to hold the data\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Iterate over all matching files\n",
    "    for filename in glob.glob(file_pattern):\n",
    "        # Load the current file into a DataFrame\n",
    "        temp_df = pd.read_csv(filename)\n",
    "        temp_df.columns = column_names\n",
    "        # Append the data from the current file to the main DataFrame\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    # Save the main DataFrame to a new file\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to hold the data\n",
    "col_name = ['Iterations', 'Time', 'variance', 'range', 'smoothness', 'log-likelihood']\n",
    "if bv:\n",
    "    if dep:\n",
    "        file_pattern = [f'batchsize_{bs}_{bs}/sum_1000_{bs}_*.csv' for bs in batch_size]\n",
    "    else:\n",
    "        file_pattern = [f'batchsize_{bs}_0/sum_1000_{bs}_*.csv' for bs in batch_size]\n",
    "else:\n",
    "    file_pattern = [f'batchsize_{bs}_{bs}/sum_1000_{bs}_*.csv' for bs in batch_size]\n",
    "output_file = [os.path.join(folder_name_sum, f'output_{bs}.csv') for bs in batch_size]\n",
    "for k in range(len(batch_size)):\n",
    "    read_files_and_concatenate(file_pattern[k], col_name, output_file[k])\n",
    "output_file.append('./outputs_sum/output_ExaGeoStat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = './fig_1K'\n",
    "if os.path.exists(fig_path):\n",
    "    print(fig_path + ' exists!')\n",
    "else:\n",
    "    os.mkdir(fig_path)\n",
    "    print(fig_path + ' is created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Set the default font size\n",
    "mpl.rcParams['font.size'] = 14\n",
    "n_replicates = 100\n",
    "\n",
    "def plot_time_boxplot(file_names, indic):\n",
    "    \"\"\"\n",
    "    Plot a boxplot of the 'Time' column for each CSV file in the list of file names.\n",
    "    \"\"\"\n",
    "    # Create an empty list to store the time data\n",
    "    time_data = []\n",
    "\n",
    "    # Loop through the file names and extract the \"Time\" column from each CSV file\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name)\n",
    "        if indic != 'combined':\n",
    "            time_data.append(df[indic])\n",
    "        else:\n",
    "            time_data.append(df['variance'].pow(2).div(df['range'].pow(df['smoothness'].mul(2))))\n",
    "    # Create a boxplot of the time data with x-axis ticks for each file name\n",
    "    bp = plt.boxplot(time_data, \n",
    "                    patch_artist=True,\n",
    "                    # notch=True, \n",
    "                    widths=0.3)\n",
    "    \n",
    "    # Set the boxplot colors\n",
    "    if bv:\n",
    "        if dep:\n",
    "            colors = plt.cm.Blues(np.linspace(0.1, 0.9, len(batch_size) + 1))\n",
    "        else:\n",
    "            colors = plt.cm.Purples(np.linspace(0.1, 0.9, len(batch_size) + 1))\n",
    "    else:\n",
    "        if grouping:\n",
    "            colors = plt.cm.Reds(np.linspace(0.1, 0.9, len(batch_size) + 1))\n",
    "        elif knn:\n",
    "            colors = plt.cm.Oranges(np.linspace(0.1, 0.9, len(batch_size) + 1))\n",
    "        else:\n",
    "            colors = plt.cm.Greens(np.linspace(0.1, 0.9, len(batch_size) + 1))\n",
    "        \n",
    "\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        \n",
    "    # Set the line width for the median line\n",
    "    for median in bp['medians']:\n",
    "        median.set_linewidth(2)\n",
    "        \n",
    "    # Set the line width for the whiskers\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set_linewidth(1.5)\n",
    "    plt.xticks(range(1, len(file_names) + 1), [2, 5, 10, 20, 40, 'Exact'])\n",
    "    # plt.xticks(range(1, len(file_names) + 1), [20, 40, 50, 100, 200, 250, 500])\n",
    "\n",
    "    # Add a title and axis labels\n",
    "    if indic == 'Time':\n",
    "        # plt.title('Average time ('+ str(n_replicates) + ' replicates)')\n",
    "        # plt.yscale('log')\n",
    "        plt.ylabel('Seconds')\n",
    "    elif indic == 'Iterations':\n",
    "        # plt.title('Boxplot of total iterations ('+ str(n_replicates) + ' replicates)')\n",
    "        # plt.yscale('log')\n",
    "        # plt.ylim(0, 450)\n",
    "        plt.ylabel('Iterations')\n",
    "    elif indic == 'variance':\n",
    "        # plt.title(r'Boxplot of $\\hat\\sigma$ ('+ str(n_replicates) + ' replicates)')\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=params[0], color='red', linestyle='--', label=r'$\\sigma=$' + str(params[0]))\n",
    "        # plt.ylim(0.3, 2.5)\n",
    "        # time_data_mean = np.abs(np.median(time_data, axis=1) - params[0])\n",
    "        # Add a legend\n",
    "        # plt.legend(loc='upper left')\n",
    "    elif indic == 'range':\n",
    "        # plt.title(r'Boxplot of $\\hat\\beta$ ('+ str(n_replicates) + ' replicates)')\n",
    "        # plt.ylim(0.04, 0.20)\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=params[1], color='red', linestyle='--', label=r'$\\beta=$' + str(params[1]))\n",
    "        # time_data_mean = np.abs(np.median(time_data, axis=1) - params[1])\n",
    "        # Add a legend\n",
    "        # plt.legend(loc='upper left')\n",
    "    elif indic == 'smoothness':\n",
    "        # plt.title(r'Boxplot of $\\hat\\nu$ ('+ str(n_replicates) + ' replicates)')\n",
    "        # plt.ylim(0.20, 1.00)\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        plt.axhline(y=params[2], color='red', linestyle='--', label=r'$\\nu=$' + str(params[2]))\n",
    "        # time_data_mean = np.abs(np.median(time_data, axis=1) - params[2])\n",
    "        # Add a legend\n",
    "        # plt.legend(loc='upper left')\n",
    "    # elif indic == 'log-likelihood':\n",
    "    #     plt.title(r'Boxplot of log-likelihood ('+ str(n_replicates) + ' replicates)')\n",
    "    #     # plt.ylim(-900, 2800)\n",
    "    \n",
    "    elif indic == 'combined':\n",
    "        plt.title(r'Boxplot of $\\frac{\\hat\\sigma^2}{\\hat\\beta^{2\\hat\\nu}}$ ('+ str(n_replicates) + ' replicates)')\n",
    "        # plt.ylim(0, 30)\n",
    "        # Add a horizontal line at y=0.5 and a text label 'true'\n",
    "        cons_esti = params[0]**2 / (params[1]**(2*params[2]))\n",
    "        plt.axhline(y=cons_esti, color='red', linestyle='--', label=r'$\\frac{\\sigma^2}{\\beta^{2\\nu}} = $' + str(round(cons_esti, 2)))\n",
    "        # time_data_mean = np.abs(np.median(time_data, axis=1) - cons_esti)\n",
    "        # Add a legend\n",
    "        # plt.legend(loc='upper left')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # title\n",
    "    if not bv:\n",
    "        if grouping:\n",
    "            plt.title('GpGp (KNN and Grouping)')\n",
    "        elif knn:\n",
    "            plt.title('GpGp (KNN)')\n",
    "        else:\n",
    "            plt.title('GpGp (base)')\n",
    "        ## Save the difference of the data\n",
    "        ## Used for quantitve description \n",
    "        # with open('./1k_' + str(params[1]) + '_' + str(params[2]) + str('_gpgp.csv')\n",
    "        #         , mode='a', newline='') as file:\n",
    "        #     writer = csv.writer(file)\n",
    "        #     writer.writerow(time_data_mean)\n",
    "    else:\n",
    "        if dep:\n",
    "            plt.title('BV (dependent)')\n",
    "        else:\n",
    "            plt.title('BV (independent)')\n",
    "        ## Save the difference of the data\n",
    "        ## Used for quantitve description \n",
    "        # with open('./1k_' + str(params[1]) + '_' + str(params[2]) + str('_bv.csv')\n",
    "        #         , mode='a', newline='') as file:\n",
    "        #     writer = csv.writer(file)\n",
    "        #     writer.writerow(time_data_mean)\n",
    "    plt.xlabel('The number of neighbors')\n",
    "    plt.savefig(os.path.join(fig_path, indic) + '_1k_' + str(params[1]) + '_' + str(params[2]) + str('.pdf'), \n",
    "                bbox_inches='tight', format = 'pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = [os.path.join(folder_name_sum, f'output_{bs}.csv') for bs in batch_size_all]\n",
    "# plot_time_boxplot(output_file, indic='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_time_boxplot(output_file, indic='log-likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_boxplot(output_file, indic='smoothness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "185e5c47242a5ceaa23e29ada14173afc2d86b943e6603ddddbe3fb4d7ad104d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
